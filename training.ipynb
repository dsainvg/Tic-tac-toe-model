{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsainvg/Tic-tac-toe-model/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01dea715",
      "metadata": {
        "id": "01dea715"
      },
      "source": [
        "# Board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0ce5b464",
      "metadata": {
        "id": "0ce5b464"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Board:\n",
        "    def __init__(self):\n",
        "        self.board = torch.zeros(9, dtype=torch.float32)\n",
        "        self.sum = 0\n",
        "        self.game = []\n",
        "\n",
        "    def printBoard(self):\n",
        "        for i in range(3):\n",
        "            print(self.board[i*3:(i+1)*3])\n",
        "\n",
        "    def _play(self, id, val):\n",
        "        if self.board[val].item() == 0:\n",
        "            self.sum += 1\n",
        "            self.board[val] = id\n",
        "            self.game.append((id, val))\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _checkWin(self, id, val):\n",
        "        b = self.board  # shorthand for readability\n",
        "        match val:\n",
        "            case 0:\n",
        "                if (b[0] == b[1]).item() and (b[1] == b[2]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[3]).item() and (b[3] == b[6]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[4]).item() and (b[4] == b[8]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "            case 1:\n",
        "                if (b[0] == b[1]).item() and (b[1] == b[2]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[1] == b[4]).item() and (b[4] == b[7]).item() and (b[1] == id).item():\n",
        "                    return True\n",
        "            case 2:\n",
        "                if (b[0] == b[1]).item() and (b[1] == b[2]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[5]).item() and (b[5] == b[8]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[4]).item() and (b[4] == b[6]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "            case 3:\n",
        "                if (b[3] == b[4]).item() and (b[4] == b[5]).item() and (b[3] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[3]).item() and (b[3] == b[6]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "            case 4:\n",
        "                if (b[3] == b[4]).item() and (b[4] == b[5]).item() and (b[3] == id).item():\n",
        "                    return True\n",
        "                if (b[1] == b[4]).item() and (b[4] == b[7]).item() and (b[1] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[4]).item() and (b[4] == b[8]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[4]).item() and (b[4] == b[6]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "            case 5:\n",
        "                if (b[3] == b[4]).item() and (b[4] == b[5]).item() and (b[3] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[5]).item() and (b[5] == b[8]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "            case 6:\n",
        "                if (b[6] == b[7]).item() and (b[7] == b[8]).item() and (b[6] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[3]).item() and (b[3] == b[6]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[4]).item() and (b[4] == b[6]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "            case 7:\n",
        "                if (b[6] == b[7]).item() and (b[7] == b[8]).item() and (b[6] == id).item():\n",
        "                    return True\n",
        "                if (b[1] == b[4]).item() and (b[4] == b[7]).item() and (b[1] == id).item():\n",
        "                    return True\n",
        "            case 8:\n",
        "                if (b[6] == b[7]).item() and (b[7] == b[8]).item() and (b[6] == id).item():\n",
        "                    return True\n",
        "                if (b[2] == b[5]).item() and (b[5] == b[8]).item() and (b[2] == id).item():\n",
        "                    return True\n",
        "                if (b[0] == b[4]).item() and (b[4] == b[8]).item() and (b[0] == id).item():\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def play(self, id, val):\n",
        "        if self._play(id, val):\n",
        "            if self._checkWin(id,val):\n",
        "                return True,\"win\"\n",
        "            if self.sum == 9:\n",
        "                return True,\"draw\"\n",
        "            return False,\"none\"\n",
        "        return True,\"invalid\"\n",
        "\n",
        "    def clear(self):\n",
        "        self.board = torch.zeros(9, dtype=torch.float32)\n",
        "        self.sum = 0\n",
        "        self.game = []\n",
        "\n",
        "    @property\n",
        "    def board_state(self):\n",
        "        return self.board\n",
        "\n",
        "    @property\n",
        "    def game_state(self):\n",
        "        return self.game\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ffae1a",
      "metadata": {
        "id": "71ffae1a"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kOMLsGILavc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOMLsGILavc8",
        "outputId": "daae2335-c78b-451b-886b-dea964b8939d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3220d447",
      "metadata": {
        "id": "3220d447"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import Categorical\n",
        "import os\n",
        "import pickle\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Board setup and test\n",
        "board = Board()\n",
        "# board.printBoard()\n",
        "# board.board_state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17b7a2f",
      "metadata": {
        "id": "d17b7a2f"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2d91377f",
      "metadata": {
        "id": "2d91377f"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "hyperparams = {\n",
        "    'input_size': 9,\n",
        "    'hidden_sizes': (256, 512, 64, 32),\n",
        "    'num_classes': 9,\n",
        "    'num_epochs': 50000,\n",
        "    'num_parallel_boards': 32,\n",
        "    'game_chances': 9,\n",
        "    'temperature': 0.60,\n",
        "    'learning_rate': 7e-4,\n",
        "    'gamma': 0.85,\n",
        "    't_end': 0.98,\n",
        "    'random_t_start': 0.45,\n",
        "    'random_t_add': 0.5,\n",
        "    'weight_decay': 1e-3,\n",
        "    'reward': {\"Win\": 2, \"Lost\": -1.9, \"Draw\": 0.05},\n",
        "    'device': device,  # Use the device configured above\n",
        "    'checkpoint_epochs': [1000,1500,2000,5000,10000,15000,20000,25000],  # List of epochs to save checkpoints (set to None or [] to disable)\n",
        "    'checkpoint_dir': '/content/drive/MyDrive/models/checkpoints'  # Directory for checkpoints\n",
        "}\n",
        "\n",
        "# Extract model architecture parameters\n",
        "input_size = hyperparams['input_size']\n",
        "hidden_sizes = hyperparams['hidden_sizes']\n",
        "num_classes = hyperparams['num_classes']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "887f9b49",
      "metadata": {
        "id": "887f9b49"
      },
      "source": [
        "### NEURALNET DESIGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c0eb0d85",
      "metadata": {
        "id": "c0eb0d85",
        "outputId": "e3c808cc-f99b-4922-9170-610efd0080bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cpu\n",
            "Optimizer: AdamW(lr=0.0007, weight_decay=0.001)\n"
          ]
        }
      ],
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, hyperparams):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(2*input_size, hidden_sizes[0])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.l3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.l4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.l5 = nn.Linear(hidden_sizes[3], num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # Move to device\n",
        "        device = hyperparams['device']\n",
        "        self.to(device)\n",
        "\n",
        "        # Initialize optimizer once\n",
        "        learning_rate = hyperparams['learning_rate']\n",
        "        weight_decay = hyperparams['weight_decay']\n",
        "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Initialize histories\n",
        "        self.loss_histories = {\"avg\": [], \"cum\": []}\n",
        "        self.all_game_histories = []\n",
        "        self.total_epochs_trained = 0\n",
        "\n",
        "        print(f\"Model initialized on {device}\")\n",
        "        print(f\"Optimizer: AdamW(lr={learning_rate}, weight_decay={weight_decay})\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        xin = torch.stack((self.relu(x), self.relu(-x)), dim=2).flatten(start_dim=1)\n",
        "        logits = torch.zeros_like(x)  # Create a tensor of all 0s\n",
        "        logits = logits.masked_fill(x != 0, float('-inf'))\n",
        "        out = self.l1(xin)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l4(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l5(out)\n",
        "        out = out + logits\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "    def _save_checkpoint(self, checkpoint_dir, epoch):\n",
        "        \"\"\"Internal method to save a checkpoint\"\"\"\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n",
        "        torch.save(self.state_dict(), checkpoint_path)\n",
        "        print(f\"  Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "    def train_model(self, hyperparams, epochs=None, start_epoch=0):\n",
        "        \"\"\"Train the model with given hyperparameters\n",
        "\n",
        "        Args:\n",
        "            hyperparams: Dictionary of hyperparameters\n",
        "            epochs: Number of epochs to train. If None, uses hyperparams['num_epochs']\n",
        "            start_epoch: Starting epoch number (for continuous training)\n",
        "        \"\"\"\n",
        "        # Extract hyperparameters\n",
        "        device = hyperparams['device']\n",
        "        num_epochs = epochs if epochs is not None else hyperparams['num_epochs']\n",
        "        num_parallel_boards = hyperparams['num_parallel_boards']\n",
        "        game_chances = hyperparams['game_chances']\n",
        "        temperature = hyperparams['temperature']\n",
        "        gamma = hyperparams['gamma']\n",
        "        t_end = hyperparams['t_end']\n",
        "        random_t_start = hyperparams['random_t_start']\n",
        "        random_t_add = hyperparams['random_t_add']\n",
        "        reward = hyperparams['reward']\n",
        "        checkpoint_epochs = hyperparams.get('checkpoint_epochs', None)\n",
        "\n",
        "        # Setup checkpoint directory if needed\n",
        "        checkpoint_dir = None\n",
        "        if checkpoint_epochs is not None and len(checkpoint_epochs) > 0:\n",
        "            checkpoint_dir = hyperparams.get('checkpoint_dir', 'checkpoints')\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            checkpoint_epochs_set = set(checkpoint_epochs)\n",
        "\n",
        "        # Local histories for this training segment\n",
        "        loss_histories = {\"avg\": [], \"cum\": []}\n",
        "        game_histories = []\n",
        "\n",
        "        # Pre-compute discount cache\n",
        "        discount_cache = {}\n",
        "        for length in range(1, game_chances + 1):\n",
        "            discount_cache[length] = torch.pow(gamma, torch.arange(length, device=device, dtype=torch.float32))\n",
        "\n",
        "        cummulative_loss = 0.0\n",
        "        avg100 = 0.0\n",
        "\n",
        "        parallel_boards = [Board() for _ in range(num_parallel_boards)]\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(start_epoch, num_epochs):\n",
        "            # Clear all boards\n",
        "            for board in parallel_boards:\n",
        "                board.clear()\n",
        "\n",
        "            # Generate active players for all boards\n",
        "            active_players = [1 if random.random() < 0.5 else 0 for _ in range(num_parallel_boards)]\n",
        "\n",
        "            # Track game data for each board\n",
        "            all_gamequeus = [[] for _ in range(num_parallel_boards)]\n",
        "            all_boards_states = [[] for _ in range(num_parallel_boards)]\n",
        "            game_finished = [False] * num_parallel_boards\n",
        "            final_results = [None] * num_parallel_boards\n",
        "\n",
        "            # Play games on all boards\n",
        "            for i in range(game_chances):\n",
        "                active_board_indices = [idx for idx, finished in enumerate(game_finished) if not finished]\n",
        "\n",
        "                if not active_board_indices:\n",
        "                    break\n",
        "\n",
        "                # Store board states for all active boards\n",
        "                for board_idx in active_board_indices:\n",
        "                    all_boards_states[board_idx].append(parallel_boards[board_idx].board_state.clone())\n",
        "\n",
        "                # BATCH PROCESS\n",
        "                batch_states = torch.stack([parallel_boards[idx].board_state for idx in active_board_indices]).to(device)\n",
        "                current_player_val = 2*(i%2) - 1\n",
        "                batch_states = batch_states * current_player_val\n",
        "                batch_predictions = self(batch_states)\n",
        "\n",
        "                # Process each board's prediction from the batch\n",
        "                for batch_idx, board_idx in enumerate(active_board_indices):\n",
        "                    board = parallel_boards[board_idx]\n",
        "                    active_player = active_players[board_idx]\n",
        "\n",
        "                    y = batch_predictions[batch_idx].unsqueeze(0)\n",
        "                    valid_mask = (board.board_state == 0).float().unsqueeze(0).to(device)\n",
        "                    num_valid = valid_mask.sum()\n",
        "\n",
        "                    # Mix model predictions with uniform\n",
        "                    t = temperature + (epoch / num_epochs) * 2 * (1 - temperature)\n",
        "                    t = min(t, t_end)\n",
        "                    if active_player != i%2:\n",
        "                        t = random_t_start + (epoch / num_epochs) * random_t_add\n",
        "                    uniform_prob = valid_mask / num_valid\n",
        "                    y = y * t + uniform_prob * (1 - t)\n",
        "                    m = Categorical(probs=y)\n",
        "                    Y_out = m.sample()\n",
        "\n",
        "                    # Make move\n",
        "                    status, win = board.play(2*(i%2) - 1, Y_out.item())\n",
        "\n",
        "                    # Store log probability\n",
        "                    if i % 2 == active_player:\n",
        "                        log_prob = m.log_prob(Y_out)\n",
        "                        all_gamequeus[board_idx].append((i, log_prob))\n",
        "\n",
        "                    # Check if game finished\n",
        "                    if status:\n",
        "                        game_finished[board_idx] = True\n",
        "                        final_results[board_idx] = (status, win)\n",
        "\n",
        "            # Calculate losses\n",
        "            all_losses = []\n",
        "\n",
        "            for board_idx in range(num_parallel_boards):\n",
        "                gamequeue = all_gamequeus[board_idx]\n",
        "                boards_states = all_boards_states[board_idx]\n",
        "\n",
        "                if final_results[board_idx] is None:\n",
        "                    continue\n",
        "\n",
        "                status, win = final_results[board_idx]\n",
        "                active_player = active_players[board_idx]\n",
        "\n",
        "                if win == \"invalid\":\n",
        "                    if len(boards_states) > 0:\n",
        "                        print(f\"Invalid move made on board {board_idx}!\")\n",
        "                        print(\"Board state:\\n\", boards_states[-1].reshape(3,3))\n",
        "                    continue\n",
        "                elif len(gamequeue) == 0:\n",
        "                    continue\n",
        "                else:\n",
        "                    # Save game history\n",
        "                    game_history = {\n",
        "                        'epoch': epoch,\n",
        "                        'board_idx': board_idx,\n",
        "                        'active_player': active_player,\n",
        "                        'game_state': parallel_boards[board_idx].game_state.copy(),\n",
        "                        'result': win,\n",
        "                        'reward': reward[\"Draw\"] if win == \"draw\" else (reward[\"Win\"] if (len(boards_states) - 1) % 2 == active_player else reward[\"Lost\"])\n",
        "                    }\n",
        "                    game_histories.append(game_history)\n",
        "\n",
        "                    if win == \"draw\":\n",
        "                        reward_value = reward[\"Draw\"]\n",
        "                    else:\n",
        "                        final_i = len(boards_states) - 1\n",
        "                        reward_value = reward[\"Win\"] if (final_i % 2) == active_player else reward[\"Lost\"]\n",
        "\n",
        "                    # Stack log_probs\n",
        "                    log_probs = torch.stack([lp for _, lp in gamequeue[::-1]])\n",
        "                    discounts = discount_cache[len(gamequeue)]\n",
        "                    loss = -(discounts * reward_value * log_probs).sum() / len(gamequeue)\n",
        "                    all_losses.append(loss)\n",
        "\n",
        "            # Update model\n",
        "            if len(all_losses) > 0:\n",
        "                self.optimizer.zero_grad()\n",
        "                total_loss = torch.stack(all_losses).mean()\n",
        "                total_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    cummulative_loss += total_loss.item()\n",
        "                    avg100 += total_loss.item()\n",
        "\n",
        "                if (epoch+1) % 100 == 0:\n",
        "                    loss_histories[\"avg\"].append(avg100)\n",
        "                    loss_histories[\"cum\"].append(cummulative_loss/(epoch+1-start_epoch))\n",
        "                    print('epoch ', epoch+1, ': loss = ', total_loss.item(),'; avg loss = ', cummulative_loss/(epoch+1-start_epoch),f\"; Avg loss of last 100 is {avg100}\", f'; boards processed = {len(all_losses)}')\n",
        "                    avg100 = 0.0\n",
        "\n",
        "        self.total_epochs_trained = num_epochs\n",
        "\n",
        "        # Append to global histories\n",
        "        self.loss_histories[\"avg\"].extend(loss_histories[\"avg\"])\n",
        "        self.loss_histories[\"cum\"].extend(loss_histories[\"cum\"])\n",
        "        self.all_game_histories.extend(game_histories)\n",
        "\n",
        "        return loss_histories, game_histories\n",
        "\n",
        "    def train_with_checkpoints(self, hyperparams):\n",
        "        \"\"\"Train model incrementally, saving at specified checkpoint epochs\n",
        "\n",
        "        Args:\n",
        "            hyperparams: Dictionary with 'checkpoint_epochs' list to train incrementally\n",
        "        \"\"\"\n",
        "        checkpoint_epochs = hyperparams.get('checkpoint_epochs', [])\n",
        "        if not checkpoint_epochs:\n",
        "            print(\"No checkpoint epochs specified, running full training\")\n",
        "            return self.train_model(hyperparams)\n",
        "\n",
        "        checkpoint_dir = hyperparams.get('checkpoint_dir', 'checkpoints')\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        sorted_checkpoints = sorted(checkpoint_epochs)\n",
        "\n",
        "        previous_epoch = 0\n",
        "        for checkpoint_epoch in sorted_checkpoints:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Training from epoch {previous_epoch} to {checkpoint_epoch}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            # Train from previous checkpoint to this one\n",
        "            self.train_model(\n",
        "                hyperparams,\n",
        "                epochs=checkpoint_epoch,\n",
        "                start_epoch=previous_epoch\n",
        "            )\n",
        "\n",
        "            # Save checkpoint\n",
        "            self._save_checkpoint(checkpoint_dir, checkpoint_epoch)\n",
        "\n",
        "            previous_epoch = checkpoint_epoch\n",
        "\n",
        "        return self.loss_histories, self.all_game_histories\n",
        "\n",
        "    def save_model(self, model_path, game_histories=None, histories_path=None):\n",
        "        \"\"\"Save model and optionally game histories\"\"\"\n",
        "        # Create directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "        # Save model\n",
        "        torch.save(self.state_dict(), model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "\n",
        "        # Save game histories if provided (use internal if not specified)\n",
        "        histories_to_save = game_histories if game_histories is not None else self.all_game_histories\n",
        "        if histories_to_save and histories_path is not None:\n",
        "            os.makedirs(os.path.dirname(histories_path), exist_ok=True)\n",
        "            with open(histories_path, 'wb') as f:\n",
        "                pickle.dump(histories_to_save, f)\n",
        "            print(f\"Game histories ({len(histories_to_save)} games) saved to {histories_path}\")\n",
        "\n",
        "model = NeuralNet(input_size, hidden_sizes, num_classes, hyperparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae694d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae694d85",
        "outputId": "bc2aaad7-5ec1-43d1-b353-c5f944d16e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with hyperparameters:\n",
            "  input_size: 9\n",
            "  hidden_sizes: (256, 512, 64, 32)\n",
            "  num_classes: 9\n",
            "  num_epochs: 50000\n",
            "  num_parallel_boards: 32\n",
            "  game_chances: 9\n",
            "  temperature: 0.6\n",
            "  learning_rate: 0.0007\n",
            "  gamma: 0.85\n",
            "  t_end: 0.98\n",
            "  random_t_start: 0.45\n",
            "  random_t_add: 0.5\n",
            "  weight_decay: 0.001\n",
            "  reward: {'Win': 2, 'Lost': -1.9, 'Draw': 0.05}\n",
            "  device: cpu\n",
            "  checkpoint_epochs: [1000, 1500, 2000, 5000, 10000, 15000, 20000, 25000]\n",
            "  checkpoint_dir: /content/drive/MyDrive/models/checkpoints\n",
            "\n",
            "============================================================\n",
            "Training from epoch 0 to 1000\n",
            "============================================================\n",
            "epoch  100 : loss =  0.8345656991004944 ; avg loss =  0.5972047436237335 ; Avg loss of last 100 is 59.72047436237335 ; boards processed = 32\n",
            "epoch  200 : loss =  0.20193548500537872 ; avg loss =  0.522906046435237 ; Avg loss of last 100 is 44.860734924674034 ; boards processed = 32\n",
            "epoch  300 : loss =  -0.6658796668052673 ; avg loss =  0.43241964402298133 ; Avg loss of last 100 is 25.14468391984701 ; boards processed = 32\n",
            "epoch  400 : loss =  0.7638963460922241 ; avg loss =  0.32219011591747404 ; Avg loss of last 100 is -0.8498468399047852 ; boards processed = 32\n",
            "epoch  500 : loss =  -0.22069817781448364 ; avg loss =  0.24049668331630528 ; Avg loss of last 100 is -8.627704708836973 ; boards processed = 32\n",
            "epoch  600 : loss =  -0.22688817977905273 ; avg loss =  0.17973935250968984 ; Avg loss of last 100 is -12.404730152338743 ; boards processed = 32\n",
            "epoch  700 : loss =  -0.3125634491443634 ; avg loss =  0.1376447639800608 ; Avg loss of last 100 is -11.492276719771326 ; boards processed = 32\n",
            "epoch  800 : loss =  -0.24954865872859955 ; avg loss =  0.0981308828725014 ; Avg loss of last 100 is -17.84662848804146 ; boards processed = 32\n",
            "epoch  900 : loss =  0.3078949451446533 ; avg loss =  0.06900338677068552 ; Avg loss of last 100 is -16.401658204384148 ; boards processed = 32\n",
            "epoch  1000 : loss =  -0.2489965409040451 ; avg loss =  0.036022835263982415 ; Avg loss of last 100 is -26.080212829634547 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_1000.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 1000 to 1500\n",
            "============================================================\n",
            "epoch  1100 : loss =  0.02289716899394989 ; avg loss =  -0.12388830007053912 ; Avg loss of last 100 is -12.388830007053912 ; boards processed = 32\n",
            "epoch  1200 : loss =  -0.8080248832702637 ; avg loss =  -0.14624104673508553 ; Avg loss of last 100 is -16.859379339963198 ; boards processed = 32\n",
            "epoch  1300 : loss =  -0.8049063682556152 ; avg loss =  -0.16263369757682086 ; Avg loss of last 100 is -19.541899926029146 ; boards processed = 32\n",
            "epoch  1400 : loss =  0.005438936408609152 ; avg loss =  -0.18335790542856556 ; Avg loss of last 100 is -24.553052898379974 ; boards processed = 32\n",
            "epoch  1500 : loss =  -0.25768405199050903 ; avg loss =  -0.1971764740284998 ; Avg loss of last 100 is -25.24507484282367 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_1500.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 1500 to 2000\n",
            "============================================================\n",
            "epoch  1600 : loss =  -0.24193663895130157 ; avg loss =  -0.19176882436499 ; Avg loss of last 100 is -19.176882436499 ; boards processed = 32\n",
            "epoch  1700 : loss =  0.024823253974318504 ; avg loss =  -0.18156741731450893 ; Avg loss of last 100 is -17.136601026402786 ; boards processed = 32\n",
            "epoch  1800 : loss =  -0.2722412943840027 ; avg loss =  -0.18918916089227422 ; Avg loss of last 100 is -20.443264804780483 ; boards processed = 32\n",
            "epoch  1900 : loss =  0.0178985595703125 ; avg loss =  -0.1992439900600584 ; Avg loss of last 100 is -22.9408477563411 ; boards processed = 32\n",
            "epoch  2000 : loss =  0.018051723018288612 ; avg loss =  -0.21977696464350446 ; Avg loss of last 100 is -30.190886297728866 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_2000.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 2000 to 5000\n",
            "============================================================\n",
            "epoch  2100 : loss =  0.3101443350315094 ; avg loss =  -0.08101942528039217 ; Avg loss of last 100 is -8.101942528039217 ; boards processed = 32\n",
            "epoch  2200 : loss =  -0.36885684728622437 ; avg loss =  -0.10434136584401131 ; Avg loss of last 100 is -12.766330640763044 ; boards processed = 32\n",
            "epoch  2300 : loss =  -0.027310211211442947 ; avg loss =  -0.10996695044605682 ; Avg loss of last 100 is -12.121811965014786 ; boards processed = 32\n",
            "epoch  2400 : loss =  0.03182138875126839 ; avg loss =  -0.08276799590908922 ; Avg loss of last 100 is -0.11711322981864214 ; boards processed = 32\n",
            "epoch  2500 : loss =  -0.2342296689748764 ; avg loss =  -0.0674293891498819 ; Avg loss of last 100 is -0.6074962113052607 ; boards processed = 32\n",
            "epoch  2600 : loss =  0.3702582120895386 ; avg loss =  -0.062277424103037146 ; Avg loss of last 100 is -3.6517598868813366 ; boards processed = 32\n",
            "epoch  2700 : loss =  0.02538735419511795 ; avg loss =  -0.05713330304416429 ; Avg loss of last 100 is -2.626857669092715 ; boards processed = 32\n",
            "epoch  2800 : loss =  -0.2862344980239868 ; avg loss =  -0.05708668428735109 ; Avg loss of last 100 is -5.676035298965871 ; boards processed = 32\n",
            "epoch  2900 : loss =  -0.015004247426986694 ; avg loss =  -0.06042705832230341 ; Avg loss of last 100 is -8.715005060192198 ; boards processed = 32\n",
            "epoch  3000 : loss =  0.3354949951171875 ; avg loss =  -0.058913578994339334 ; Avg loss of last 100 is -4.529226504266262 ; boards processed = 32\n",
            "epoch  3100 : loss =  -0.2772088050842285 ; avg loss =  -0.06739894609580832 ; Avg loss of last 100 is -15.225261711049825 ; boards processed = 32\n",
            "epoch  3200 : loss =  0.6149295568466187 ; avg loss =  -0.07169905908347574 ; Avg loss of last 100 is -11.90003019478172 ; boards processed = 32\n",
            "epoch  3300 : loss =  0.3286694884300232 ; avg loss =  -0.073790308561785 ; Avg loss of last 100 is -9.888530230149627 ; boards processed = 32\n",
            "epoch  3400 : loss =  0.03660915046930313 ; avg loss =  -0.07419283140866485 ; Avg loss of last 100 is -7.942562841810286 ; boards processed = 32\n",
            "epoch  3500 : loss =  0.022655531764030457 ; avg loss =  -0.07305924295835818 ; Avg loss of last 100 is -5.7189004654064775 ; boards processed = 32\n",
            "epoch  3600 : loss =  -0.27595385909080505 ; avg loss =  -0.07645014593319502 ; Avg loss of last 100 is -12.73136905557476 ; boards processed = 32\n",
            "epoch  3700 : loss =  -0.2638068199157715 ; avg loss =  -0.07621998667306103 ; Avg loss of last 100 is -7.253743851091713 ; boards processed = 32\n",
            "epoch  3800 : loss =  -0.24919673800468445 ; avg loss =  -0.07722140389779168 ; Avg loss of last 100 is -9.424549671821296 ; boards processed = 32\n",
            "epoch  3900 : loss =  0.28048643469810486 ; avg loss =  -0.08395588816903335 ; Avg loss of last 100 is -20.517660505138338 ; boards processed = 32\n",
            "epoch  4000 : loss =  0.001958001172170043 ; avg loss =  -0.0825131454434013 ; Avg loss of last 100 is -5.510103365639225 ; boards processed = 32\n",
            "epoch  4100 : loss =  0.020385023206472397 ; avg loss =  -0.08403916177539421 ; Avg loss of last 100 is -11.455948841525242 ; boards processed = 32\n",
            "epoch  4200 : loss =  -0.24022553861141205 ; avg loss =  -0.08680656237570061 ; Avg loss of last 100 is -14.4921974982135 ; boards processed = 32\n",
            "epoch  4300 : loss =  0.014085118658840656 ; avg loss =  -0.0884508689529384 ; Avg loss of last 100 is -12.46256136521697 ; boards processed = 32\n",
            "epoch  4400 : loss =  -0.5793716907501221 ; avg loss =  -0.09355442933912855 ; Avg loss of last 100 is -21.0936318221502 ; boards processed = 32\n",
            "epoch  4500 : loss =  -0.021908771246671677 ; avg loss =  -0.09076000997647643 ; Avg loss of last 100 is -2.369394527282566 ; boards processed = 32\n",
            "epoch  4600 : loss =  -0.5712244510650635 ; avg loss =  -0.09787482375386529 ; Avg loss of last 100 is -27.574516818858683 ; boards processed = 32\n",
            "epoch  4700 : loss =  0.010969098657369614 ; avg loss =  -0.10374895081667798 ; Avg loss of last 100 is -25.647625444980804 ; boards processed = 32\n",
            "epoch  4800 : loss =  -0.6067935228347778 ; avg loss =  -0.10910038920653668 ; Avg loss of last 100 is -25.35892257327214 ; boards processed = 32\n",
            "epoch  4900 : loss =  -0.8576931357383728 ; avg loss =  -0.11343099623824197 ; Avg loss of last 100 is -23.468799312599003 ; boards processed = 32\n",
            "epoch  5000 : loss =  -0.7788751721382141 ; avg loss =  -0.1175811389676334 ; Avg loss of last 100 is -23.7935278119985 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_5000.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 5000 to 10000\n",
            "============================================================\n",
            "epoch  5100 : loss =  0.026852713897824287 ; avg loss =  -0.06734748780494555 ; Avg loss of last 100 is -6.734748780494556 ; boards processed = 32\n",
            "epoch  5200 : loss =  -0.22373425960540771 ; avg loss =  -0.07753280588658526 ; Avg loss of last 100 is -8.771812396822497 ; boards processed = 32\n",
            "epoch  5300 : loss =  0.015436122193932533 ; avg loss =  -0.07557063733693212 ; Avg loss of last 100 is -7.164630023762584 ; boards processed = 32\n",
            "epoch  5400 : loss =  -0.7663426995277405 ; avg loss =  -0.09114010852528737 ; Avg loss of last 100 is -13.784852209035307 ; boards processed = 32\n",
            "epoch  5500 : loss =  -0.7928177118301392 ; avg loss =  -0.07718641024455428 ; Avg loss of last 100 is -2.1371617121621966 ; boards processed = 32\n",
            "epoch  5600 : loss =  0.03472940996289253 ; avg loss =  -0.0723107906570658 ; Avg loss of last 100 is -4.793269271962345 ; boards processed = 32\n",
            "epoch  5700 : loss =  0.3152675926685333 ; avg loss =  -0.07540316113403865 ; Avg loss of last 100 is -9.395738399587572 ; boards processed = 32\n",
            "epoch  5800 : loss =  -0.24298039078712463 ; avg loss =  -0.0731417211194639 ; Avg loss of last 100 is -5.731164101744071 ; boards processed = 32\n",
            "epoch  5900 : loss =  0.026926949620246887 ; avg loss =  -0.07255921523009116 ; Avg loss of last 100 is -6.7899168115109205 ; boards processed = 32\n",
            "epoch  6000 : loss =  0.037916600704193115 ; avg loss =  -0.0763584941814188 ; Avg loss of last 100 is -11.055200474336743 ; boards processed = 32\n",
            "epoch  6100 : loss =  -0.2327105700969696 ; avg loss =  -0.07546750204108486 ; Avg loss of last 100 is -6.655758063774556 ; boards processed = 32\n",
            "epoch  6200 : loss =  0.026365093886852264 ; avg loss =  -0.08404616739503884 ; Avg loss of last 100 is -17.84114862885326 ; boards processed = 32\n",
            "epoch  6300 : loss =  -0.5653152465820312 ; avg loss =  -0.08372521860148902 ; Avg loss of last 100 is -7.987383307889104 ; boards processed = 32\n",
            "epoch  6400 : loss =  -0.5078645944595337 ; avg loss =  -0.08949663102111247 ; Avg loss of last 100 is -16.452499247621745 ; boards processed = 32\n",
            "epoch  6500 : loss =  -0.25090059638023376 ; avg loss =  -0.09533926088688895 ; Avg loss of last 100 is -17.71360790077597 ; boards processed = 32\n",
            "epoch  6600 : loss =  -0.2599979341030121 ; avg loss =  -0.0950519733033434 ; Avg loss of last 100 is -9.074265955016017 ; boards processed = 32\n",
            "epoch  6700 : loss =  0.03388865664601326 ; avg loss =  -0.09647881364764865 ; Avg loss of last 100 is -11.930825915653259 ; boards processed = 32\n",
            "epoch  6800 : loss =  0.026024671271443367 ; avg loss =  -0.09556489521210702 ; Avg loss of last 100 is -8.002828180789948 ; boards processed = 32\n",
            "epoch  6900 : loss =  -0.5393317341804504 ; avg loss =  -0.10079464153104804 ; Avg loss of last 100 is -19.493007527198642 ; boards processed = 32\n",
            "epoch  7000 : loss =  -0.2914328873157501 ; avg loss =  -0.10056836311158258 ; Avg loss of last 100 is -9.626907314173877 ; boards processed = 32\n",
            "epoch  7100 : loss =  0.019797220826148987 ; avg loss =  -0.1013218594193902 ; Avg loss of last 100 is -11.63917855755426 ; boards processed = 32\n",
            "epoch  7200 : loss =  -0.5259305834770203 ; avg loss =  -0.10137346418468621 ; Avg loss of last 100 is -10.245716425590217 ; boards processed = 32\n",
            "epoch  7300 : loss =  -0.2401629239320755 ; avg loss =  -0.10287534735104797 ; Avg loss of last 100 is -13.591677701100707 ; boards processed = 32\n",
            "epoch  7400 : loss =  -0.2710946500301361 ; avg loss =  -0.10382298560192188 ; Avg loss of last 100 is -12.56186653720215 ; boards processed = 32\n",
            "epoch  7500 : loss =  0.3048918545246124 ; avg loss =  -0.10667357605993748 ; Avg loss of last 100 is -17.50877470523119 ; boards processed = 32\n",
            "epoch  7600 : loss =  -0.28616461157798767 ; avg loss =  -0.10927033249611179 ; Avg loss of last 100 is -17.418924340046942 ; boards processed = 32\n",
            "epoch  7700 : loss =  -1.04005765914917 ; avg loss =  -0.11478037041542982 ; Avg loss of last 100 is -25.804135631769896 ; boards processed = 32\n",
            "epoch  7800 : loss =  0.02208656258881092 ; avg loss =  -0.11651289304685114 ; Avg loss of last 100 is -16.329100409522653 ; boards processed = 32\n",
            "epoch  7900 : loss =  -0.8433107137680054 ; avg loss =  -0.11893892581703078 ; Avg loss of last 100 is -18.686784338206053 ; boards processed = 32\n",
            "epoch  8000 : loss =  0.026738222688436508 ; avg loss =  -0.1218410755211177 ; Avg loss of last 100 is -20.600341693963856 ; boards processed = 32\n",
            "epoch  8100 : loss =  0.09841427952051163 ; avg loss =  -0.12161711125018736 ; Avg loss of last 100 is -11.489818312227726 ; boards processed = 32\n",
            "epoch  8200 : loss =  -0.20225341618061066 ; avg loss =  -0.12467213211479247 ; Avg loss of last 100 is -21.937777891755104 ; boards processed = 32\n",
            "epoch  8300 : loss =  -0.7855071425437927 ; avg loss =  -0.12707487741555792 ; Avg loss of last 100 is -20.39627270400524 ; boards processed = 32\n",
            "epoch  8400 : loss =  0.042621903121471405 ; avg loss =  -0.13054483931634903 ; Avg loss of last 100 is -24.505358204245567 ; boards processed = 32\n",
            "epoch  8500 : loss =  0.2624720335006714 ; avg loss =  -0.12996800367800254 ; Avg loss of last 100 is -11.035559197422117 ; boards processed = 32\n",
            "epoch  8600 : loss =  -0.22998051345348358 ; avg loss =  -0.13090080928872339 ; Avg loss of last 100 is -16.354900566395372 ; boards processed = 32\n",
            "epoch  8700 : loss =  -0.8776195645332336 ; avg loss =  -0.1339437202592003 ; Avg loss of last 100 is -24.34885151963681 ; boards processed = 32\n",
            "epoch  8800 : loss =  0.005643163807690144 ; avg loss =  -0.13506110218635417 ; Avg loss of last 100 is -17.64042334910482 ; boards processed = 32\n",
            "epoch  8900 : loss =  -0.2650289833545685 ; avg loss =  -0.13583729679827602 ; Avg loss of last 100 is -16.533269205130637 ; boards processed = 32\n",
            "epoch  9000 : loss =  -0.5211551189422607 ; avg loss =  -0.13799554326664656 ; Avg loss of last 100 is -22.21671555330977 ; boards processed = 32\n",
            "epoch  9100 : loss =  -0.2603567838668823 ; avg loss =  -0.13936961501461975 ; Avg loss of last 100 is -19.433248493354768 ; boards processed = 32\n",
            "epoch  9200 : loss =  -0.5725826025009155 ; avg loss =  -0.14073991586908788 ; Avg loss of last 100 is -19.69222509022802 ; boards processed = 32\n",
            "epoch  9300 : loss =  -0.8682001829147339 ; avg loss =  -0.14137259341475858 ; Avg loss of last 100 is -16.794505033292808 ; boards processed = 32\n",
            "epoch  9400 : loss =  -0.21334391832351685 ; avg loss =  -0.14322087527247443 ; Avg loss of last 100 is -22.2696995154256 ; boards processed = 32\n",
            "epoch  9500 : loss =  0.3261759877204895 ; avg loss =  -0.14516563208137329 ; Avg loss of last 100 is -23.073493167292327 ; boards processed = 32\n",
            "epoch  9600 : loss =  -0.5513789653778076 ; avg loss =  -0.14711057523958912 ; Avg loss of last 100 is -23.463301735930145 ; boards processed = 32\n",
            "epoch  9700 : loss =  -0.545673668384552 ; avg loss =  -0.14842988692892795 ; Avg loss of last 100 is -20.911822463851422 ; boards processed = 32\n",
            "epoch  9800 : loss =  -0.2622198462486267 ; avg loss =  -0.15150036432271008 ; Avg loss of last 100 is -29.581280183047056 ; boards processed = 32\n",
            "epoch  9900 : loss =  -0.2262980043888092 ; avg loss =  -0.1540935702298112 ; Avg loss of last 100 is -27.856745377066545 ; boards processed = 32\n",
            "epoch  10000 : loss =  -1.1281774044036865 ; avg loss =  -0.15613509166885634 ; Avg loss of last 100 is -25.616964218206704 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_10000.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 10000 to 15000\n",
            "============================================================\n",
            "epoch  10100 : loss =  -0.20648406445980072 ; avg loss =  -0.13119793403428048 ; Avg loss of last 100 is -13.119793403428048 ; boards processed = 32\n",
            "epoch  10200 : loss =  0.033996257930994034 ; avg loss =  -0.11470699931262061 ; Avg loss of last 100 is -9.821606459096074 ; boards processed = 32\n",
            "epoch  10300 : loss =  -0.2097754031419754 ; avg loss =  -0.1340848673492049 ; Avg loss of last 100 is -17.284060342237353 ; boards processed = 32\n",
            "epoch  10400 : loss =  -0.23224908113479614 ; avg loss =  -0.1312377924460452 ; Avg loss of last 100 is -12.269656773656607 ; boards processed = 32\n",
            "epoch  10500 : loss =  -0.24915292859077454 ; avg loss =  -0.13527368820738048 ; Avg loss of last 100 is -15.141727125272155 ; boards processed = 32\n",
            "epoch  10600 : loss =  0.04390770196914673 ; avg loss =  -0.14719048994593323 ; Avg loss of last 100 is -20.677449863869697 ; boards processed = 32\n",
            "epoch  10700 : loss =  -0.2661522626876831 ; avg loss =  -0.13828095222291137 ; Avg loss of last 100 is -8.482372588478029 ; boards processed = 32\n",
            "epoch  10800 : loss =  0.040088996291160583 ; avg loss =  -0.1336941082519479 ; Avg loss of last 100 is -10.158620045520365 ; boards processed = 32\n",
            "epoch  10900 : loss =  0.3975081741809845 ; avg loss =  -0.13633630862925203 ; Avg loss of last 100 is -15.747391164768487 ; boards processed = 32\n",
            "epoch  11000 : loss =  -0.24141192436218262 ; avg loss =  -0.1394253082529176 ; Avg loss of last 100 is -16.722630486590788 ; boards processed = 32\n",
            "epoch  11100 : loss =  0.04690764844417572 ; avg loss =  -0.13547611139735885 ; Avg loss of last 100 is -9.598414284177125 ; boards processed = 32\n",
            "epoch  11200 : loss =  0.022798389196395874 ; avg loss =  -0.13368102511876107 ; Avg loss of last 100 is -11.393507605418563 ; boards processed = 32\n",
            "epoch  11300 : loss =  -0.2515328526496887 ; avg loss =  -0.13086038014941062 ; Avg loss of last 100 is -9.7012640517205 ; boards processed = 32\n",
            "epoch  11400 : loss =  0.023840008303523064 ; avg loss =  -0.13217229314564194 ; Avg loss of last 100 is -14.92271620966494 ; boards processed = 32\n",
            "epoch  11500 : loss =  0.023077504709362984 ; avg loss =  -0.13562417613606279 ; Avg loss of last 100 is -18.395053800195456 ; boards processed = 32\n",
            "epoch  11600 : loss =  -0.5256516933441162 ; avg loss =  -0.13748109466643654 ; Avg loss of last 100 is -16.53348726220429 ; boards processed = 32\n",
            "epoch  11700 : loss =  0.030409440398216248 ; avg loss =  -0.13990622360012767 ; Avg loss of last 100 is -17.87082865391858 ; boards processed = 32\n",
            "epoch  11800 : loss =  -0.21262013912200928 ; avg loss =  -0.1390544115195775 ; Avg loss of last 100 is -12.45736061502248 ; boards processed = 32\n",
            "epoch  11900 : loss =  0.02876436524093151 ; avg loss =  -0.14301349911177041 ; Avg loss of last 100 is -21.427707577124238 ; boards processed = 32\n",
            "epoch  12000 : loss =  0.022004716098308563 ; avg loss =  -0.14431644684146158 ; Avg loss of last 100 is -16.907245370559394 ; boards processed = 32\n",
            "epoch  12100 : loss =  0.033917538821697235 ; avg loss =  -0.14433620074686285 ; Avg loss of last 100 is -14.473127885488793 ; boards processed = 32\n",
            "epoch  12200 : loss =  0.31637927889823914 ; avg loss =  -0.14592133545327338 ; Avg loss of last 100 is -17.920916428789496 ; boards processed = 32\n",
            "epoch  12300 : loss =  0.033405907452106476 ; avg loss =  -0.14593075153650717 ; Avg loss of last 100 is -14.61379053676501 ; boards processed = 32\n",
            "epoch  12400 : loss =  0.028758764266967773 ; avg loss =  -0.14942751001246507 ; Avg loss of last 100 is -22.985295495949686 ; boards processed = 32\n",
            "epoch  12500 : loss =  0.6206743121147156 ; avg loss =  -0.1510772065316327 ; Avg loss of last 100 is -19.066992299165577 ; boards processed = 32\n",
            "epoch  12600 : loss =  -0.4501587152481079 ; avg loss =  -0.15343785309528288 ; Avg loss of last 100 is -21.24540171865374 ; boards processed = 32\n",
            "epoch  12700 : loss =  -0.8295634984970093 ; avg loss =  -0.15549045869330358 ; Avg loss of last 100 is -20.885820424184203 ; boards processed = 32\n",
            "epoch  12800 : loss =  -0.271974116563797 ; avg loss =  -0.1573520812055462 ; Avg loss of last 100 is -20.761588903609663 ; boards processed = 32\n",
            "epoch  12900 : loss =  0.0117868110537529 ; avg loss =  -0.15937268112834285 ; Avg loss of last 100 is -21.594947896664962 ; boards processed = 32\n",
            "epoch  13000 : loss =  -0.5915358662605286 ; avg loss =  -0.16104416618294393 ; Avg loss of last 100 is -20.951723276637495 ; boards processed = 32\n",
            "epoch  13100 : loss =  -0.26305070519447327 ; avg loss =  -0.16336400594006503 ; Avg loss of last 100 is -23.295919865369797 ; boards processed = 32\n",
            "epoch  13200 : loss =  -0.5340889692306519 ; avg loss =  -0.16450414737002575 ; Avg loss of last 100 is -19.984853169880807 ; boards processed = 32\n",
            "epoch  13300 : loss =  -0.49275004863739014 ; avg loss =  -0.1663889890653787 ; Avg loss of last 100 is -22.670392331667244 ; boards processed = 32\n",
            "epoch  13400 : loss =  -0.5293399095535278 ; avg loss =  -0.1675022164626759 ; Avg loss of last 100 is -20.42387205734849 ; boards processed = 32\n",
            "epoch  13500 : loss =  -0.502444326877594 ; avg loss =  -0.16959086068333792 ; Avg loss of last 100 is -24.060476418584585 ; boards processed = 32\n",
            "epoch  13600 : loss =  -0.5335566401481628 ; avg loss =  -0.16975872371229342 ; Avg loss of last 100 is -17.563392972573638 ; boards processed = 32\n",
            "epoch  13700 : loss =  0.02751028910279274 ; avg loss =  -0.17089279047237094 ; Avg loss of last 100 is -21.17191938351607 ; boards processed = 32\n",
            "epoch  13800 : loss =  0.019475845620036125 ; avg loss =  -0.17178492094443706 ; Avg loss of last 100 is -20.47937484108843 ; boards processed = 32\n",
            "epoch  13900 : loss =  -0.8319094777107239 ; avg loss =  -0.17399948677816726 ; Avg loss of last 100 is -25.815298845991492 ; boards processed = 32\n",
            "epoch  14000 : loss =  0.04081600904464722 ; avg loss =  -0.1771474528421386 ; Avg loss of last 100 is -29.991812933702022 ; boards processed = 32\n",
            "epoch  14100 : loss =  0.0058381203562021255 ; avg loss =  -0.1800738153415136 ; Avg loss of last 100 is -29.712831531651318 ; boards processed = 32\n",
            "epoch  14200 : loss =  -0.5772441029548645 ; avg loss =  -0.18279427445885849 ; Avg loss of last 100 is -29.433309826999903 ; boards processed = 32\n",
            "epoch  14300 : loss =  -0.5749707221984863 ; avg loss =  -0.1839383046339174 ; Avg loss of last 100 is -23.198757198639214 ; boards processed = 32\n",
            "epoch  14400 : loss =  -0.2692078649997711 ; avg loss =  -0.18561890958031158 ; Avg loss of last 100 is -25.78849222752615 ; boards processed = 32\n",
            "epoch  14500 : loss =  0.014340786263346672 ; avg loss =  -0.18735832880081013 ; Avg loss of last 100 is -26.389277450274676 ; boards processed = 32\n",
            "epoch  14600 : loss =  0.011914924718439579 ; avg loss =  -0.18950899869123217 ; Avg loss of last 100 is -28.628914376022294 ; boards processed = 32\n",
            "epoch  14700 : loss =  -1.1657323837280273 ; avg loss =  -0.19091003053203012 ; Avg loss of last 100 is -25.53574952087365 ; boards processed = 32\n",
            "epoch  14800 : loss =  0.0305892713367939 ; avg loss =  -0.19122698224178142 ; Avg loss of last 100 is -20.61237126000924 ; boards processed = 32\n",
            "epoch  14900 : loss =  0.019833136349916458 ; avg loss =  -0.19318988630960918 ; Avg loss of last 100 is -28.74092815653421 ; boards processed = 32\n",
            "epoch  15000 : loss =  -0.5488364696502686 ; avg loss =  -0.19439505698889842 ; Avg loss of last 100 is -25.34484202740714 ; boards processed = 32\n",
            "  Checkpoint saved: /content/drive/MyDrive/models/checkpoints/model_epoch_15000.pth\n",
            "\n",
            "============================================================\n",
            "Training from epoch 15000 to 20000\n",
            "============================================================\n",
            "epoch  15100 : loss =  -0.8406977653503418 ; avg loss =  -0.12355520642362534 ; Avg loss of last 100 is -12.355520642362535 ; boards processed = 32\n",
            "epoch  15200 : loss =  -0.5114262700080872 ; avg loss =  -0.15155199369997718 ; Avg loss of last 100 is -17.9548780976329 ; boards processed = 32\n",
            "epoch  15300 : loss =  -0.27204784750938416 ; avg loss =  -0.15216117451355482 ; Avg loss of last 100 is -15.337953614071012 ; boards processed = 32\n",
            "epoch  15400 : loss =  -0.22109194099903107 ; avg loss =  -0.1568026341296354 ; Avg loss of last 100 is -17.072701297787717 ; boards processed = 32\n",
            "epoch  15500 : loss =  0.038439229130744934 ; avg loss =  -0.15513351817865623 ; Avg loss of last 100 is -14.845705437473953 ; boards processed = 32\n",
            "epoch  15600 : loss =  0.5793680548667908 ; avg loss =  -0.1709277184312911 ; Avg loss of last 100 is -24.98987196944654 ; boards processed = 32\n",
            "epoch  15700 : loss =  -0.29728734493255615 ; avg loss =  -0.16809082458506705 ; Avg loss of last 100 is -15.106946150772274 ; boards processed = 32\n",
            "epoch  15800 : loss =  0.02570945769548416 ; avg loss =  -0.16417466221679206 ; Avg loss of last 100 is -13.676152563886717 ; boards processed = 32\n",
            "epoch  15900 : loss =  0.02780391275882721 ; avg loss =  -0.1663150913988486 ; Avg loss of last 100 is -18.34385248553008 ; boards processed = 32\n",
            "epoch  16000 : loss =  0.01692664623260498 ; avg loss =  -0.1691191381230892 ; Avg loss of last 100 is -19.43555586412549 ; boards processed = 32\n",
            "epoch  16100 : loss =  0.0207766592502594 ; avg loss =  -0.17163552311722677 ; Avg loss of last 100 is -19.67993730586022 ; boards processed = 32\n",
            "epoch  16200 : loss =  0.027520693838596344 ; avg loss =  -0.17585325660501744 ; Avg loss of last 100 is -22.224832497071475 ; boards processed = 32\n",
            "epoch  16300 : loss =  -0.25174954533576965 ; avg loss =  -0.17750385914989658 ; Avg loss of last 100 is -19.731108968844637 ; boards processed = 32\n",
            "epoch  16400 : loss =  -0.2202196717262268 ; avg loss =  -0.17650303159896533 ; Avg loss of last 100 is -16.349227343685925 ; boards processed = 32\n",
            "epoch  16500 : loss =  -0.2543344795703888 ; avg loss =  -0.17991843542819455 ; Avg loss of last 100 is -22.773408903740346 ; boards processed = 32\n",
            "epoch  16600 : loss =  -0.5398148894309998 ; avg loss =  -0.17847892352370764 ; Avg loss of last 100 is -15.688624495640397 ; boards processed = 32\n",
            "epoch  16700 : loss =  0.0218752920627594 ; avg loss =  -0.18109741044770036 ; Avg loss of last 100 is -22.299320123158395 ; boards processed = 32\n",
            "epoch  16800 : loss =  -0.5749880075454712 ; avg loss =  -0.1811727928040879 ; Avg loss of last 100 is -18.24542928626761 ; boards processed = 32\n",
            "epoch  16900 : loss =  -0.2564467191696167 ; avg loss =  -0.18065637641750265 ; Avg loss of last 100 is -17.136088145896792 ; boards processed = 32\n",
            "epoch  17000 : loss =  -0.24756623804569244 ; avg loss =  -0.18430561499383474 ; Avg loss of last 100 is -25.36411479441449 ; boards processed = 32\n",
            "epoch  17100 : loss =  -0.8139033317565918 ; avg loss =  -0.18893958700059946 ; Avg loss of last 100 is -28.16190271358937 ; boards processed = 32\n",
            "epoch  17200 : loss =  -0.24790677428245544 ; avg loss =  -0.18963498060860068 ; Avg loss of last 100 is -20.42382463766262 ; boards processed = 32\n",
            "epoch  17300 : loss =  0.02479553036391735 ; avg loss =  -0.1913475284714672 ; Avg loss of last 100 is -22.902358145453036 ; boards processed = 32\n",
            "epoch  17400 : loss =  0.021944310516119003 ; avg loss =  -0.19223805949144054 ; Avg loss of last 100 is -21.272027295082808 ; boards processed = 32\n",
            "epoch  17500 : loss =  -0.24960476160049438 ; avg loss =  -0.19192281734807184 ; Avg loss of last 100 is -18.435700590722263 ; boards processed = 32\n",
            "epoch  17600 : loss =  -0.29947909712791443 ; avg loss =  -0.1942409727859754 ; Avg loss of last 100 is -25.21948587335646 ; boards processed = 32\n",
            "epoch  17700 : loss =  0.34074947237968445 ; avg loss =  -0.19444024773516166 ; Avg loss of last 100 is -19.962139641400427 ; boards processed = 32\n",
            "epoch  17800 : loss =  -0.2003536820411682 ; avg loss =  -0.19551185164379214 ; Avg loss of last 100 is -22.444515717681497 ; boards processed = 32\n",
            "epoch  17900 : loss =  0.024370890110731125 ; avg loss =  -0.19500710015244388 ; Avg loss of last 100 is -18.087405839469284 ; boards processed = 32\n",
            "epoch  18000 : loss =  -0.5333983302116394 ; avg loss =  -0.1966201294923958 ; Avg loss of last 100 is -24.339798035100102 ; boards processed = 32\n",
            "epoch  18100 : loss =  -0.8469048738479614 ; avg loss =  -0.19729958145641685 ; Avg loss of last 100 is -21.76831403770484 ; boards processed = 32\n",
            "epoch  18200 : loss =  -0.537488579750061 ; avg loss =  -0.19908174620769387 ; Avg loss of last 100 is -25.432885349728167 ; boards processed = 32\n",
            "epoch  18300 : loss =  -0.8512235283851624 ; avg loss =  -0.201493513426403 ; Avg loss of last 100 is -27.86700644250959 ; boards processed = 32\n",
            "epoch  18400 : loss =  -0.254984587430954 ; avg loss =  -0.20180711656058145 ; Avg loss of last 100 is -21.215601998846978 ; boards processed = 32\n",
            "epoch  18500 : loss =  -0.24314208328723907 ; avg loss =  -0.20427138956336005 ; Avg loss of last 100 is -28.805667165783234 ; boards processed = 32\n",
            "epoch  18600 : loss =  0.32992932200431824 ; avg loss =  -0.2056253318222702 ; Avg loss of last 100 is -25.301331088412553 ; boards processed = 32\n",
            "epoch  18700 : loss =  -0.2513568103313446 ; avg loss =  -0.2061667109572099 ; Avg loss of last 100 is -22.565635981503874 ; boards processed = 32\n"
          ]
        }
      ],
      "source": [
        "# Training using train_with_checkpoints method\n",
        "print(\"Starting training with hyperparameters:\")\n",
        "for key, value in hyperparams.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "loss_histories, all_game_histories = model.train_with_checkpoints(hyperparams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HlTgeBGD6ySX",
      "metadata": {
        "id": "HlTgeBGD6ySX"
      },
      "source": [
        "# Saving of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf5cca7",
      "metadata": {
        "id": "fbf5cca7"
      },
      "outputs": [],
      "source": [
        "# Save model and game histories using the class method\n",
        "model_filename = '/content/drive/MyDrive/models/model.pth'\n",
        "histories_filename = '/content/drive/MyDrive/models/game_histories.pkl'\n",
        "\n",
        "model.save_model(model_filename, game_histories=all_game_histories, histories_path=histories_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F3zLdmBO-gCc",
      "metadata": {
        "id": "F3zLdmBO-gCc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Create the models directory if it doesn't exist\n",
        "output_dir = '/content/drive/MyDrive/models'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Plot Average Loss History\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(loss_histories[\"avg\"], label='Average Loss (last 100 epochs)')\n",
        "plt.title(\"Average Loss History\")\n",
        "plt.xlabel(\"Epochs (in batches of 100)\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'average_loss_history.png'))\n",
        "plt.show()\n",
        "\n",
        "# Plot Cumulative Loss History (if available)\n",
        "if len(loss_histories[\"cum\"]) > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(loss_histories[\"cum\"], label='Cumulative Average Loss')\n",
        "    plt.title(\"Cumulative Average Loss History\")\n",
        "    plt.xlabel(\"Epochs (in batches of 100)\")\n",
        "    plt.ylabel(\"Cumulative Average Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'cumulative_loss_history.png'))\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cumulative loss history is empty. Please re-run the training cell after the fix.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a_Hnpirm_miS",
      "metadata": {
        "collapsed": true,
        "id": "a_Hnpirm_miS"
      },
      "outputs": [],
      "source": [
        "loss_histories[\"avg\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}